name: ci

on: [push]

jobs:
  test:
    runs-on: ubuntu-latest
    env:
      GROUP: weaveworksdemos
      COMMIT: ${{ github.sha }}
      REPO: orders
    steps:
      - uses: actions/setup-python@v2
        with:
          python-version: '3.10'
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas
          pip install numpy
      - run: sudo apt update
      - run: sudo apt install inotify-tools
      - run: inotifywait -mr /home/runner/work/orders/orders/ --format '%T;%w;%f;%e' --timefmt %T -o /home/runner/inotify-logs.csv & echo 'basak'
      - uses: actions/checkout@v2

      - run: touch starting_test_SetupJDK18_25
      - run: rm starting_test_SetupJDK18_25
      - name: Set up JDK 1.8
        uses: actions/setup-java@v1
        with:
          java-version: 1.8

      - run: touch starting_test_CacheMavenpackages_30
      - run: rm starting_test_CacheMavenpackages_30
      - name: Cache Maven packages
        uses: actions/cache@v2
        with:
          path: ~/.m2
          key: ${{ runner.os }}-m2-${{ hashFiles('**/pom.xml') }}
          restore-keys: ${{ runner.os }}-m2

      - run: touch starting_test_BuildwithMaven_37
      - run: rm starting_test_BuildwithMaven_37
      - name: Build with Maven
        run: mvn -B -DskipTests package --file pom.xml

      - run: touch starting_test_UnitTests_40
      - run: rm starting_test_UnitTests_40
      - name: Unit Tests
        run: mvn -q test

      - run: touch starting_test_IntegrationTests_43
      - run: rm starting_test_IntegrationTests_43
      - name: Integration Tests
        run: mvn integration-test

      # Build docker image for service
      - run: touch starting_test_Builddockerimage_47
      - run: rm starting_test_Builddockerimage_47
      - name: Build docker image
        uses: docker/build-push-action@v1
        with:
          push: false
          dockerfile: docker/orders/Dockerfile.github
          repository: ${{ env.GROUP }}/${{ env.REPO }}
          tag_with_ref: true
          tag_with_sha: true
          tags: ${{ github.sha }}

      # Build docker image for mock service
      - run: touch starting_test_Buildmockdockerimage_58
      - run: rm starting_test_Buildmockdockerimage_58
      - name: Build mock docker image
        uses: docker/build-push-action@v1
        with:
          push: false
          path: test/json-server/
          dockerfile: test/json-server/Dockerfile
          repository: weaveworksdemos/json-server
          tags: latest
          
      # Run simple test against built container
      - run: touch starting_test_Testdockerimage_68
      - run: rm starting_test_Testdockerimage_68
      - name: Test docker image
        env:
          DOCKER_BUILDKIT: 1
        run: ./test/test.sh container.py --tag ${GITHUB_SHA}

      # Upload coverage results to coveralls
      - run: touch starting_test_SubmitCoveralls_74
      - run: rm starting_test_SubmitCoveralls_74
      - name: Submit Coveralls
        env:
          COVERALLS_TOKEN: ${{ secrets.COVERALLS_TOKEN }}
        run: mvn -DrepoToken=${COVERALLS_TOKEN} -DserviceJobId=${GITHUB_RUN_ID} -Dbranch=${GITHUB_REF} -DpullRequest=${GITHUB_HEAD_REF} -DserviceName=GITHUB verify jacoco:report coveralls:report

      # Push to dockerhub
      - run: touch starting_test_PushtoDockerHub_80
      - run: rm starting_test_PushtoDockerHub_80
      - name: Push to Docker Hub
        uses: docker/build-push-action@v1
        if: startsWith(github.ref, 'refs/tags/v') || github.ref == 'refs/heads/master'
        with:
          username: ${{ secrets.DOCKER_USER }}
          password: ${{ secrets.DOCKER_PASS }}
          dockerfile: docker/orders/Dockerfile.github
          repository: ${{ env.GROUP }}/${{ env.REPO }}
          tag_with_ref: true
          tag_with_sha: true
      - run: touch starting_finished_finished_8979874
      - run: rm starting_finished_finished_8979874
      - uses: jannekem/run-python-script-action@v1
        with:
          script: |
            import pandas as pd
            import numpy as np
            import os
            df = pd.read_csv('/home/runner/inotify-logs.csv', sep = ';', names=['time', 'watched_filename', 'event_filename', 'event_name'])
            df['event_filename'] = df['event_filename'].replace(np.nan, '')
            steps = {}
            starting_indexes = df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'CREATE')].index.to_list() + [df.shape[0]]
            ending_indexes = [0] + df[(df['event_filename'].str.contains('starting_')) & (df['event_name'] == 'DELETE')].index.to_list()
            starting_df = df[df['event_filename'].str.contains('starting_')]
            touch_file_names = ['setup'] + [x.replace('starting_', '') for x in starting_df['event_filename'].value_counts().index.to_list()]
            for starting_index, ending_index, touch_file_name in zip(starting_indexes, ending_indexes, touch_file_names):
                steps[touch_file_name] = (ending_index, starting_index)
            df['watched_filename'] = df['watched_filename'] + df['event_filename']
            df.drop('event_filename', axis=1, inplace=True)
            df.rename(columns={'watched_filename':'file_name'}, inplace=True)
            modify_df = df[df['event_name'] == 'MODIFY']
            file_names = modify_df['file_name'].value_counts().index.to_list()
            info = []
            for file_name in file_names:
                last_access_step = ''
                last_modify_step = ''
                creation_step = ''
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].shape[0] == 0: last_modify_index = -1
                else: last_modify_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'MODIFY')].index.to_list()[-1]
                last_access_index = 0
                if df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].shape[0] > 0:
                    last_access_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'ACCESS')].index.to_list()[-1]
                else:
                    last_access_index = -1
                    last_access_step = 'Not provided'
                if last_access_index < last_modify_index:
                    try:
                        creation_index = df[(df['file_name'] == file_name) & (df['event_name'] == 'CREATE')].index.to_list()[0]
                    except:
                        creation_index = -1
                        creation_step = 'Not provided'
                    for touch_file_name, (starting_index, ending_index) in steps.items():
                        if (last_access_index > starting_index) and (last_access_index < ending_index):
                            last_access_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (last_modify_index > starting_index) and (last_modify_index < ending_index):
                            last_modify_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                        if (creation_index > starting_index) and (creation_index < ending_index):
                            creation_step = touch_file_name if touch_file_name == 'setup' else touch_file_name.split('_')[1]
                    if '/home/runner/work/orders/orders/.git/' not in file_name:
                        info.append({'file_name': file_name, 'last_access_index': last_access_index, 'last_modify_index': last_modify_index, 'creation_index': creation_index, 'last_access_step':last_access_step , 'last_modify_step':last_modify_step, 'creation_step': creation_step})
            info_df = pd.DataFrame(info)
            step_statistics = []
            for step, (starting_index, ending_index) in steps.items():
                step_name = step if step == 'setup' else step.split('_')[1]
                if step_name == 'finished': continue
                c = info_df['creation_step'] == step_name
                m = info_df['last_modify_step'] == step_name
                a = info_df['last_access_index'] > -1
                t = (info_df['last_modify_index'] > info_df['last_access_index']) & (info_df['last_access_index'] != -1) # never accessed after last modify (but accessed at least once)
                cma = info_df[c & m & a].shape[0]
                cma_ = info_df[c & m & ~a].shape[0]
                cmt = info_df[c & m & t].shape[0]
                cm_a = info_df[c & ~m & a].shape[0]
                cm_a_ = info_df[c & ~m & ~a].shape[0]
                cm_t = info_df[c & ~m & t].shape[0]
                c_ma = info_df[~c & m & a].shape[0]
                c_ma_ = info_df[~c & m & ~a].shape[0]
                c_mt = info_df[~c & m & t].shape[0]
                c_m_a = info_df[~c & ~m & a].shape[0]
                c_m_a_ = info_df[~c & ~m & ~a].shape[0]
                c_m_t = info_df[~c & ~m & t].shape[0]
                created_file_count = info_df[c].shape[0]
                modified_file_count = info_df[m].shape[0]
                starting_time = list(map(int, df.iloc[starting_index]['time'].split(':')))
                if ending_index == len(df): ending_time = list(map(int, df.iloc[ending_index-1]['time'].split(':')))
                else: ending_time = list(map(int, df.iloc[ending_index]['time'].split(':')))
                hour = ending_time[0] - starting_time[0]
                if starting_time[1] > ending_time[1]:
                    minute = ending_time[1] - starting_time[1] + 60
                    hour -= 1
                else: minute = ending_time[1] - starting_time[1]
                if starting_time[2] > ending_time[2]:
                    second = ending_time[2] - starting_time[2] + 60
                    minute -= 1
                else: second = ending_time[2] - starting_time[2]
                total_seconds = second + (minute * 60) + (hour * 60 * 60)
                if step_name != '':
                    step_statistics.append({'step_name': step_name, '#c': created_file_count, '#m': modified_file_count, 
                    'cma': cma, 'cma_': cma_, 'cmt': cmt, 'cm_a': cm_a, 'cm_a_': cm_a_, 'cm_t': cm_t, 'c_ma': c_ma, 'c_ma_': c_ma_, 'c_mt': c_mt, 'c_m_a': c_m_a, 'c_m_a_': c_m_a_, 'c_m_t': c_m_t, 'time': total_seconds})
            os.mkdir('optimizing-ci-builds-ci-analysis')
            step_df = pd.DataFrame(step_statistics)
            step_df.to_csv('/home/runner/work/orders/orders/optimizing-ci-builds-ci-analysis/steps.csv')
            info_df.to_csv('/home/runner/work/orders/orders/optimizing-ci-builds-ci-analysis/files.csv')
      - run: cp /home/runner/inotify-logs.csv /home/runner/work/orders/orders/optimizing-ci-builds-ci-analysis/
      - name: Pushes analysis to another repository
        id: push_directory
        uses: cpina/github-action-push-to-another-repository@main
        env:
          API_TOKEN_GITHUB: ${{ secrets.API_TOKEN_GITHUB }}
        with:
          source-directory: 'optimizing-ci-builds-ci-analysis'
          destination-github-username: 'optimizing-ci-builds'
          destination-repository-name: 'ci-analyzes'
          target-directory: 'orders/1666796577/.github/workflows/main.yaml/test'

